# Unified configuration file for the spatial building embeddings pipeline
# This is the actual configuration file for this project.
# DINOv3 configuration variant
#
# This file is organized by type of configuration rather than by workflow:
# - [global] section: Shared settings used across all workflows
# - [paths] section: All pipeline file and directory paths
# - [embedding_model] section: Model settings for embedding generation
# - [training_model] section: Model architecture settings for training
# - [training] section: Training hyperparameters and settings
# - [data] section: Data processing settings (splits, neighbors, etc.)
# - [infrastructure] section: Device, workers, and performance settings
# - [logging] section: Logging and monitoring settings
#
# Workflows automatically read from the relevant sections based on their needs.

[global]
# Random seed for reproducibility (used by workflows that don't specify their own seed)
seed = 42

# Base directory for all log files (mandatory)
# All workflows will create log files within this directory
log_dir = "/home/awolson/scratch/spatial-building-embeddings/logs"

[paths]
# Pipeline directory paths (shared across workflows)
intermediates_dir = "/home/awolson/scratch/spatial-building-embeddings/intermediates"      # Output of process_tar, input to merge_and_split
embeddings_dir = "/home/awolson/scratch/spatial-building-embeddings/embeddings-dinov3"            # Output of generate_embeddings, input to merge_and_split
merged_dir = "/home/awolson/scratch/spatial-building-embeddings/merged-dinov3"                    # Output of merge_and_split, input to triplet_training
fingerprints_dir = "/home/awolson/scratch/spatial-building-embeddings/fingerprints"          # Output of compute_fingerprints

# Training data paths
train_parquet_path = "/home/awolson/scratch/spatial-building-embeddings/merged-dinov3/train.parquet"
val_parquet_path = "/home/awolson/scratch/spatial-building-embeddings/merged-dinov3/val.parquet"
difficulty_metadata_path = "/home/awolson/scratch/spatial-building-embeddings/difficulty/difficulty_metadata.parquet"  # Output of difficulty_metadata, input to triplet_training

# Training output paths
checkpoint_dir = "/home/awolson/scratch/spatial-building-embeddings/checkpoints/triplet"

[embedding_model]
# Model settings for embedding generation (generate_embeddings workflow)
# DINOv3 models: facebook/dinov3-vits16-pretrain-lvd1689m (384 dim), 
#                 facebook/dinov3-vitb16-pretrain-lvd1689m (768 dim),
#                 facebook/dinov3-vitl16-pretrain-lvd1689m (1024 dim),
#                 facebook/dinov3-vith16-pretrain-lvd1689m (1280 dim),
#                 facebook/dinov3-vit7b16-pretrain-lvd1689m (4096 dim)
model_name = "facebook/dinov3-vit7b16-pretrain-lvd1689m"  # ViT-7B/16: 4096 dimensions
pooling_type = "pooler_output"  # Use pooler_output for DINOv3 (recommended)
batch_size = 16  # Batch size for inference (reduced for 7B model - requires H100 80GB GPU)

[training_model]
input_dim = 4096         # DINOv3 ViT-7B/16 embedding dimension (from pooler_output)
output_dim = 256         # Output embedding dimension (fixed)

[training]
num_epochs = 50         # Number of training epochs

# Checkpointing and validation
save_every_n_epochs = 5      # Save checkpoint every N epochs
validate_every_n_epochs = 1  # Run validation every N epochs
# resume_from_checkpoint = null  # Path to checkpoint to resume from (optional, omit to use default: None)
early_stopping_patience = 3  # Validations with no improvement before stopping (0 disables)

# Retrieval metrics
retrieval_metric_top_k = [1, 5, 10, 100, 1000]
retrieval_metric_max_queries = 4096
retrieval_metric_per_building_limit = 4

# Data sampling for memory reduction (useful for Optuna tuning)
# Set these to reduce memory usage during hyperparameter tuning
# Sampling is done by building_id to preserve building integrity (all images from selected buildings are included)
# sample_fraction = null        # Fraction of buildings to sample (0.0-1.0), null = load full dataset
# sample_buildings = null       # Number of buildings to sample (takes precedence over sample_fraction), null = load full dataset
# val_sample_fraction = null    # Fraction of buildings to sample for validation (0.0-1.0), null = load full dataset
# val_sample_buildings = null   # Number of buildings to sample for validation (takes precedence over val_sample_fraction), null = load full dataset
# Example for 10% of buildings: sample_fraction = 0.1
# Example for 1000 buildings: sample_buildings = 1000
sample_fraction = 0.25
val_sample_fraction = 0.25

# Best training configuration (for fetch_best_and_train.py)
best_training_trial_name_pattern = ".*-trial-.*"  # Regex pattern to match Optuna trial run names in WandB
best_training_metric_name = "val/retrieval_recall@100"  # Metric name to use for selecting best run from WandB

[data]
# Data processing settings
# Split ratios (must sum to 1.0)
train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# Streaming batch size for merge_and_split (rows per batch in pass 2)
# Lower values use less memory but may be slower
# Note: This batch_size is for merge_and_split streaming, distinct from infrastructure.batch_size in [infrastructure] section used for difficulty_metadata
# batch_size = 100000  # Default: 100,000 rows per batch

# Difficulty metadata parameters
neighbors = 150                    # Number of neighbours to retain per anchor
k0_for_local_scale = 50           # Neighbour rank used to define the local scale L(a)
sample_fraction_for_bands = 0.03  # Fraction of anchors sampled to calibrate band edges
pca_components = 32               # Number of PCA components to reduce fingerprints to

[infrastructure]
# Device and performance settings
# device, num_workers, and pin_memory are determined dynamically in the code

# Difficulty metadata performance settings
distance_dtype = "float32"  # Floating point precision: "float32" or "float64"
batch_size = 100000         # Number of anchors to process per BallTree query batch (for difficulty_metadata)
row_group_size = 50000      # Row group size for the output parquet writer

[fingerprints]
image_size = 16  # Size of the square fingerprint image (e.g., 16x16)

[logging]
# Logging and monitoring settings
log_every_n_batches = 100  # Log metrics every N batches (for training)

# Weights & Biases configuration
wandb_enabled = true        # Enable Weights & Biases logging
wandb_project = "spatial-building-embeddings-dinov3"  # wandb project name
# wandb_run_name = null       # Optional explicit run name (omit to use default: None, auto-generate)
wandb_mode = "online"       # Use "online" to sync immediately, "offline" to defer
